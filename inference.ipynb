{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables before importing TensorFlow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Custom Modules\n",
    "from model.vae import Encoder, Decoder, AutoencoderKL\n",
    "from model.unet import UNetModelSmall\n",
    "from trainer import LatentDiffusionTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "hparas = {\n",
    "    'BATCH_SIZE': 32,\n",
    "    'Z_DIM': 4, # Latent channels\n",
    "    'IMAGE_SIZE': 128,\n",
    "}\n",
    "\n",
    "SEQ_EMB_PATH = './seqemb/seq_emb_test.npy'\n",
    "TEST_DATA_PATH = './dataset/dataset/testData.pkl'\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "CHECKPOINT_PATH = f\"{CHECKPOINT_DIR}/tf_checkpoint.weights.h5\"\n",
    "OUTPUT_DIR = './inference/demo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hardware Setup ---\n",
    "def setup_hardware():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Set memory growth\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"GPUs detected: {len(gpus)}\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_hardware()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Loading ---\n",
    "def get_vae_models():\n",
    "    \"\"\"Load and return VAE (Encoder/Decoder) with weights loaded.\"\"\"\n",
    "    # We use the same cached files as in cup3.py\n",
    "    decoder_weights_fpath = keras.utils.get_file(\n",
    "                origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/decoder.h5\",\n",
    "                file_hash=\"6d3c5ba91d5cc2b134da881aaa157b2d2adc648e5625560e3ed199561d0e39d5\",\n",
    "            )\n",
    "\n",
    "    encoder_weights_fpath = keras.utils.get_file(\n",
    "        origin=\"https://huggingface.co/divamgupta/stable-diffusion-tensorflow/resolve/main/encoder_newW.h5\",\n",
    "        file_hash=\"56a2578423c640746c5e90c0a789b9b11481f47497f817e65b44a1a5538af754\",\n",
    "    )\n",
    "\n",
    "    print(\"[VAE] Loading Decoder...\")\n",
    "    decoder = Decoder()\n",
    "    latent = keras.layers.Input((16,16,4))\n",
    "    decoder_model = keras.models.Model(latent, decoder(latent))\n",
    "    decoder_model.load_weights(decoder_weights_fpath)\n",
    "\n",
    "    print(\"[VAE] Loading Encoder...\")\n",
    "    encoder = Encoder()\n",
    "    inp_img = keras.layers.Input((128,128,3))\n",
    "    encoder_model = keras.models.Model(inp_img, encoder(inp_img))\n",
    "    encoder_model.load_weights(encoder_weights_fpath)\n",
    "    \n",
    "    return encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_diffusion_model():\n",
    "    print(\"[Model] Loading VAE...\")\n",
    "    encoder_model, decoder_model = get_vae_models()\n",
    "    \n",
    "    # Freeze VAE\n",
    "    encoder_model.trainable = False\n",
    "    decoder_model.trainable = False\n",
    "    \n",
    "    print(\"[Model] Initializing UNet...\")\n",
    "    unet = UNetModelSmall()\n",
    "    ema_unet = UNetModelSmall()\n",
    "\n",
    "    # Build UNet (Force build with dummy input)\n",
    "    # Shape: x=(N, 16, 16, 4), t=(N,), c=(N, 77, 768)\n",
    "    # Note: UNet call expects [x, t, c]\n",
    "    x_in = keras.Input(shape=(16, 16, 4))\n",
    "    t_in = keras.Input(shape=(512,)) # Timestep embedding\n",
    "    c_in = keras.Input(shape=(77, 768))\n",
    "    unet([x_in, t_in, c_in])\n",
    "    ema_unet([x_in, t_in, c_in])\n",
    "    \n",
    "    print(\"[Model] Creating LatentDiffusionTrainer...\")\n",
    "    diffusion_model = LatentDiffusionTrainer(unet, ema_unet, encoder_model, decoder_model)\n",
    "    \n",
    "    # Compile dummy to allow loading weights if needed (though we use load_weights)\n",
    "    # But usually creating the object is enough.\n",
    "    \n",
    "    return diffusion_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(diffusion_model, path):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"[Checkpoint] Loading weights from {path}...\")\n",
    "        try:\n",
    "            # Force KID build if necessary for loading (though for inference strictly it might not be needed if variables match)\n",
    "             # But LatentDiffusionTrainer structure includes KID metric so load_weights might complain if layers don't match\n",
    "            dummy_img = tf.zeros((1, 128, 128, 3))\n",
    "            diffusion_model.kid.update_state(dummy_img, dummy_img)\n",
    "            \n",
    "            diffusion_model.load_weights(path, skip_mismatch=True)\n",
    "            print(\"[Checkpoint] Loaded successfully.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"[Checkpoint] Failed to load: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"[Checkpoint] File not found: {path}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Loading ---\n",
    "def testing_dataset_generator(batch_size):\n",
    "    # Load Embeddings\n",
    "    print(f\"[Data] Loading embeddings from {SEQ_EMB_PATH}...\")\n",
    "    if not os.path.exists(SEQ_EMB_PATH):\n",
    "        raise FileNotFoundError(f\"{SEQ_EMB_PATH} not found.\")\n",
    "    \n",
    "    captions_emb = np.load(SEQ_EMB_PATH)\n",
    "    # Shape check: (819, 77, 768)\n",
    "    print(f\"[Data] Embeddings shape: {captions_emb.shape}\")\n",
    "    \n",
    "    # Handle dimensions if needed (similar to input_pipeline)\n",
    "    if captions_emb.ndim == 4 and captions_emb.shape[1] == 1:\n",
    "        captions_emb = np.squeeze(captions_emb, axis=1)\n",
    "    elif captions_emb.ndim == 5 and captions_emb.shape[2] == 1:\n",
    "        captions_emb = np.squeeze(captions_emb, axis=2)\n",
    "\n",
    "    captions_emb = captions_emb.astype(np.float32)\n",
    "\n",
    "    # Load IDs\n",
    "    print(f\"[Data] Loading IDs from {TEST_DATA_PATH}...\")\n",
    "    data = pd.read_pickle(TEST_DATA_PATH)\n",
    "    # Assuming 'ID' column exists or index is ID\n",
    "    # User snippet: index = data['ID'].values\n",
    "    if 'ID' in data.columns:\n",
    "        index = data['ID'].values\n",
    "    else:\n",
    "        print(\"[Data] 'ID' column not found, using index as ID.\")\n",
    "        index = data.index.values\n",
    "        \n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((captions_emb, index))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset, len(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference Functions ---\n",
    "def inference_testset(output_folder=OUTPUT_DIR):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    print(\"[Inference] Starting inference on full test set...\")\n",
    "    diffusion_model = build_diffusion_model()\n",
    "    load_checkpoint(diffusion_model, CHECKPOINT_PATH)\n",
    "    \n",
    "    dataset, num_samples = testing_dataset_generator(hparas['BATCH_SIZE'])\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for step, (batch_emb, batch_ids) in enumerate(dataset):\n",
    "        print(f\"Processing batch {step+1}...\")\n",
    "        batch_size = tf.shape(batch_emb)[0]\n",
    "        \n",
    "        # Generate images\n",
    "        # diffusion_model.generate_images expects (batch_size, diffusion_steps, seq_emb)\n",
    "        # We use a reasonable step count for inference (e.g., 50 or 100)\n",
    "        diffusion_steps = 30 # Can be increased for better quality\n",
    "        generated_images = diffusion_model.generate_images(batch_size, diffusion_steps, batch_emb)\n",
    "        \n",
    "        # Save images\n",
    "        for i in range(batch_size):\n",
    "            img = generated_images[i].numpy() # Already [0, 1] from generate_images\n",
    "            img_id = batch_ids[i]\n",
    "            \n",
    "            # Format filename\n",
    "            if isinstance(img_id, (int, np.integer)):\n",
    "                 filename = f\"inference_{img_id:04d}.jpg\"\n",
    "            else:\n",
    "                 filename = f\"inference_{img_id}.jpg\"\n",
    "                 \n",
    "            save_path = os.path.join(output_folder, filename)\n",
    "            plt.imsave(save_path, img)\n",
    "            \n",
    "    print(f\"[Inference] Finished. Time taken: {time.time() - start_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_one(idx_to_infer, diffusion_model=None, captions_emb=None, dataset_df=None):\n",
    "    \"\"\"\n",
    "    Generate image for a single specific ID from the test set and display it.\n",
    "    idx_to_infer can be an integer index or a specific ID string depending on dataset.\n",
    "    \"\"\"\n",
    "    print(f\"[Inference] Generating one image for ID/Index: {idx_to_infer}...\")\n",
    "    \n",
    "    if diffusion_model is None:\n",
    "        diffusion_model = build_diffusion_model()\n",
    "        load_checkpoint(diffusion_model, CHECKPOINT_PATH)\n",
    "    \n",
    "    # Load Data Manually if not provided\n",
    "    if captions_emb is None:\n",
    "        print(\"[Inference] Loading embeddings (uncached)...\")\n",
    "        captions_emb = np.load(SEQ_EMB_PATH)\n",
    "        # Fix dims\n",
    "        if captions_emb.ndim == 4 and captions_emb.shape[1] == 1:\n",
    "            captions_emb = np.squeeze(captions_emb, axis=1)\n",
    "        elif captions_emb.ndim == 5 and captions_emb.shape[2] == 1:\n",
    "            captions_emb = np.squeeze(captions_emb, axis=2)\n",
    "            \n",
    "    if dataset_df is None:\n",
    "        print(\"[Inference] Loading dataframe (uncached)...\")\n",
    "        dataset_df = pd.read_pickle(TEST_DATA_PATH)\n",
    "    \n",
    "    data = dataset_df # alias\n",
    "    \n",
    "    # Find the row\n",
    "    if 'ID' in data.columns:\n",
    "        # Match ID\n",
    "        # Convert to same type for comparison\n",
    "        ids = data['ID'].values\n",
    "        # Try finding index\n",
    "        matches = np.where(ids == idx_to_infer)[0]\n",
    "        if len(matches) > 0:\n",
    "            target_idx = matches[0]\n",
    "        else:\n",
    "            print(f\"ID {idx_to_infer} not found. Using as 0-based index.\")\n",
    "            target_idx = int(idx_to_infer)\n",
    "    else:\n",
    "        target_idx = int(idx_to_infer)\n",
    "        \n",
    "    if target_idx >= len(captions_emb):\n",
    "        print(f\"Index {target_idx} out of bounds.\")\n",
    "        return\n",
    "\n",
    "    target_emb = captions_emb[target_idx]\n",
    "    target_text = data.iloc[target_idx]['Captions'] if 'Captions' in data.columns else \"Unknown Caption\"\n",
    "    \n",
    "    # Add batch dimension\n",
    "    target_emb = tf.expand_dims(target_emb, 0) # (1, 77, 768)\n",
    "    \n",
    "    # Generate\n",
    "    diffusion_steps = 50\n",
    "    generated_image = diffusion_model.generate_images(1, diffusion_steps, target_emb)\n",
    "    generated_image = generated_image[0].numpy()\n",
    "    \n",
    "    # Display\n",
    "    print(f\"Caption: {target_text}\")\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(generated_image)\n",
    "    plt.title(f\"Generated Image (ID: {idx_to_infer})\\n{target_text[:50]}...\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    out_path = f\"inference_{idx_to_infer}_single.jpg\"\n",
    "    plt.savefig(out_path)\n",
    "    print(f\"Saved inference result to {out_path}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # inference_testset()\n",
    "    \n",
    "    # Initialize model once for loop\n",
    "    diffusion_model = build_diffusion_model()\n",
    "    load_checkpoint(diffusion_model, CHECKPOINT_PATH)\n",
    "    \n",
    "    # Pre-load data\n",
    "    print(\"[Main] Pre-loading data...\")\n",
    "    all_captions_emb = np.load(SEQ_EMB_PATH)\n",
    "    if all_captions_emb.ndim == 4 and all_captions_emb.shape[1] == 1:\n",
    "        all_captions_emb = np.squeeze(all_captions_emb, axis=1)\n",
    "    elif all_captions_emb.ndim == 5 and all_captions_emb.shape[2] == 1:\n",
    "        all_captions_emb = np.squeeze(all_captions_emb, axis=2)\n",
    "        \n",
    "    all_dataset_df = pd.read_pickle(TEST_DATA_PATH)\n",
    "    \n",
    "    for i in range(10):\n",
    "        inference_one(i, diffusion_model=diffusion_model, captions_emb=all_captions_emb, dataset_df=all_dataset_df)    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
